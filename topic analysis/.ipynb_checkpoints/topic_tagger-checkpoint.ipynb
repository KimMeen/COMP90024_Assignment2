{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from ahocorapy.keywordtree import KeywordTree\n",
    "import sys\n",
    "sys.path.append('..\\\\sentiment analysis\\\\release')\n",
    "import sentiment_prediction as senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KeywordWeight(searchResult, words, weights):\n",
    "    '''\n",
    "    This function selects the keywords (in searchResult) with their weights from the dictionary records.\n",
    "    '''\n",
    "    keyword = []\n",
    "    keyword_weight = []\n",
    "    for result in searchResult:\n",
    "        keyword.append(result[0])\n",
    "    for k in keyword:\n",
    "        for i in range(len(words)):\n",
    "            if words[i] == k:\n",
    "                keyword_weight.append(weights[i])\n",
    "                break\n",
    "    return keyword, keyword_weight\n",
    "        \n",
    "def scoring(keyword, weight, real_sentiment, intended_sentiment, sentilevel):\n",
    "    '''\n",
    "    Calculate the score based on this formula: Score = (weights 1 + weight 2 +...+ weight n) * discount factor\n",
    "    '''\n",
    "    score = 0\n",
    "    for i in range(len(weight)):\n",
    "        score += float(weight[i])\n",
    "    if real_sentiment == intended_sentiment:\n",
    "        discount = sentilevel\n",
    "    else:\n",
    "        discount = -sentilevel\n",
    "    score = score * discount\n",
    "    return score\n",
    "\n",
    "def searcher(filepath):\n",
    "    '''\n",
    "    Matching the words in dictionary with the tweet provided by user.\n",
    "    '''\n",
    "    kwtree_word = []\n",
    "    kwtree_weight = []\n",
    "    f = open(filepath)\n",
    "    for line in f:\n",
    "        word, weight = line.split(' ')\n",
    "        word = word.replace('_', ' ')\n",
    "        kwtree_word.append(word)\n",
    "        weight = weight.split('\\n')[0]\n",
    "        kwtree_weight.append(weight)\n",
    "    f.close()\n",
    "    kwtree = KeywordTree(case_insensitive=True)\n",
    "    for word in kwtree_word:\n",
    "        kwtree.add(word)\n",
    "    kwtree.finalize()\n",
    "    return kwtree, kwtree_word, kwtree_weight\n",
    "\n",
    "def topicker(tweet, topics, topic_dict_path, intended_sentiments, analysor):\n",
    "    '''\n",
    "    Warpping the topic selection in this function. Please note:\n",
    "    \n",
    "    1. It chooses the best match to return, but you can avoid \n",
    "       this selection mechanism and return the scores list to store in CouchDB.\n",
    "    \n",
    "    2. The performance of this mechanism highly depends on the quality of \n",
    "       dictionaries and intended sentiments definded by user.\n",
    "    '''\n",
    "    \n",
    "    def scores_checker(scores):\n",
    "        Flag = True\n",
    "        if max(scores) != 0.0:            \n",
    "            for i in range(len(scores)):\n",
    "                if scores[i] != 0.0:\n",
    "                    Flag = False\n",
    "                    break\n",
    "        return Flag\n",
    "    \n",
    "    scores = []\n",
    "    prediction = analysor.prediction(tweet)\n",
    "    real_senti = prediction[0]\n",
    "    sentilevel = prediction[1]\n",
    "    for i in range(len(topic_dict_path)):\n",
    "        intended_sentiment = intended_sentiments[i]\n",
    "        dictionary = topic_dict_path[i]\n",
    "        this_searcher, dict_words, dict_weights = searcher(dictionary)\n",
    "        search_result = this_searcher.search_all(tweet)\n",
    "        keywords, keywords_weights = KeywordWeight(search_result, dict_words, dict_weights)\n",
    "        scores.append(scoring(keywords, keywords_weights, intended_sentiment, real_senti, sentilevel))\n",
    "    if scores_checker(scores):\n",
    "        matched_topic = 'NONE OF THESE'\n",
    "        return matched_topic\n",
    "    else:\n",
    "        max_index = scores.index(max(scores))\n",
    "        matched_topic = topics[max_index]\n",
    "        return matched_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: smoking makes me feeling better \n",
      "\n",
      "Topic matched: smoking\n"
     ]
    }
   ],
   "source": [
    "tweet = \"smoking makes me feeling better.\"\n",
    "\n",
    "topics = ['fast food', 'smoking', 'alcohols']\n",
    "topics_dictionary_path = ['fastfood.txt', 'smoking.txt', 'alcohols.txt']\n",
    "intended_sentiments = ['POSITIVE', 'POSITIVE', 'POSITIVE']\n",
    "modelpath = 'D:\\\\COMP90024_Assignment2\\\\sentiment analysis\\\\sentiment_lstm.h5'\n",
    "pklpath = 'D:\\\\COMP90024_Assignment2\\\\sentiment analysis\\\\training_data\\\\large\\\\sentiment140-freqdist.pkl'\n",
    "analysor = senti.sentianalysor(modelpath, pklpath, stemmer = False)\n",
    "\n",
    "tweet = analysor.preprocess_tweet(tweet)\n",
    "print('Tweet:', tweet, '\\n')\n",
    "\n",
    "matched = topicker(tweet, topics, topics_dictionary_path, intended_sentiments, analysor)\n",
    "print('Topic matched:', matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
