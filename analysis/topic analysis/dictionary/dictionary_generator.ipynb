{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    A basic function that gets the related words\n",
    "    derived from concept net API.\n",
    "    This function is used as a baseline only.\n",
    "'''\n",
    "def get_related(key_word):\n",
    "    result = {}\n",
    "    obj = requests.get('http://api.conceptnet.io/related/c/en/'+key_word+'?filter=/c/en').json()\n",
    "    for relate in obj['related']:\n",
    "        related_word = relate['@id'].lstrip('/c/en/')\n",
    "        related_weight = relate['weight']\n",
    "        result.update({related_word:related_weight})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Using queue to get the related words recursively\n",
    "    limit: set the upper limit of the related word number\n",
    "'''\n",
    "def get_all_related(key_word,limit=100):\n",
    "    result = {key_word:1}\n",
    "    q = queue.PriorityQueue()\n",
    "    q.put((-1,key_word))\n",
    "    count = 0\n",
    "    while (not q.empty() and count <= limit):\n",
    "        ele = q.get()\n",
    "        word = ele[1]\n",
    "        weight = -ele[0]\n",
    "        obj = requests.get('http://api.conceptnet.io/related/c/en/'+word+'?filter=/c/en').json()\n",
    "        for relate in obj['related']:\n",
    "            related_word = relate['@id'].lstrip('/c/en/')\n",
    "            if related_word not in result:\n",
    "                #print(\"%s can be added\" %related_word)\n",
    "                related_weight = relate['weight']\n",
    "                result.update({related_word:related_weight * weight})\n",
    "                q.put((-related_weight * weight,related_word))\n",
    "                count += 1\n",
    "            else:\n",
    "                #print(\"%s cannot be added since it's duplicated\" %related_word)\n",
    "                pass\n",
    "    #rank the result by weight\n",
    "    result_order_list=sorted(result.items(),key=lambda x:x[1],reverse=True)\n",
    "    result_order_dict = dict(result_order_list)\n",
    "    return result_order_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_all_related(\"fast_food\",50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fast_food': 1,\n",
       " 'flip_burgers': 0.971,\n",
       " 'burger_king': 0.777,\n",
       " 'mickey_d': 0.766,\n",
       " 'golden_arches': 0.74,\n",
       " 'mcdonalds': 0.74,\n",
       " 'burger_flipper': 0.689,\n",
       " \"macca's\": 0.687,\n",
       " \"mcdonald's\": 0.661,\n",
       " 'hamburgers': 0.612,\n",
       " 'burgers': 0.606,\n",
       " 'burger': 0.602,\n",
       " 'taco_bell': 0.595,\n",
       " 'drive_thru': 0.583,\n",
       " 'mcdonald': 0.578,\n",
       " 'hamburger': 0.568,\n",
       " 'sandwich_shop': 0.568,\n",
       " 'maccas': 0.563,\n",
       " 'heeseburgers': 0.558,\n",
       " 'junk_food': 0.557,\n",
       " 'kfc': 0.55,\n",
       " 'onvenience_stores': 0.548,\n",
       " 'slow_food': 0.545,\n",
       " 'vada_pav': 0.54,\n",
       " 'hicken_nuggets': 0.525,\n",
       " 'heeseburger': 0.52,\n",
       " 'atery': 0.515,\n",
       " 'restaurants': 0.512,\n",
       " 'fatburger': 0.512,\n",
       " 'ateries': 0.509,\n",
       " 'restaurant': 0.505,\n",
       " 'greasy_spoon': 0.505,\n",
       " 'bar_and_grill': 0.502,\n",
       " 'fast_casual': 0.502,\n",
       " 'ground_beef': 0.498,\n",
       " 'veggie_burger': 0.496,\n",
       " 'tater_tot': 0.49,\n",
       " 'arby': 0.48,\n",
       " 'takeout': 0.479,\n",
       " 'fries': 0.477,\n",
       " 'steak_house': 0.473,\n",
       " 'onvenience_store': 0.472,\n",
       " 'hamburger_steak': 0.47,\n",
       " 'special_sauce': 0.467,\n",
       " 'diners': 0.464,\n",
       " 'tater_tots': 0.463,\n",
       " 'pizza_hut': 0.462,\n",
       " 'resturant': 0.462,\n",
       " 'fried_chicken': 0.459,\n",
       " 'heese_sandwich': 0.458,\n",
       " 'french_fries': 0.447631,\n",
       " 'macdonalds': 0.445689,\n",
       " 'french_fry': 0.442776,\n",
       " 'snack_bar': 0.441805,\n",
       " 'mcdonaldization': 0.440834}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    store the result into a txt file\n",
    "\"\"\"\n",
    "def store_in_txt(result, filepath):\n",
    "    f = open(filepath, \"a+\")\n",
    "    for word,weight in result.items():\n",
    "        f.write(word+\" \"+str(weight)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    result = get_all_related(\"fast_food\",50)\n",
    "    store_in_txt(result,\"result.txt\")\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
