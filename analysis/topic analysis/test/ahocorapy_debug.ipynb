{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ahocorapy.keywordtree import KeywordTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwtree1 = KeywordTree(case_insensitive=True)\n",
    "kwtree1.add('smoke')\n",
    "kwtree1.add('smoking')\n",
    "kwtree1.add('tobacco')\n",
    "kwtree1.add('cigarette')\n",
    "kwtree1.add('inhale')\n",
    "kwtree1.finalize()\n",
    "\n",
    "kwtree2 = KeywordTree(case_insensitive=True)\n",
    "kwtree2.add('fast food')\n",
    "kwtree2.add('burgers')\n",
    "kwtree2.add('mcdonalds')\n",
    "kwtree2.add('sandwich')\n",
    "kwtree2.add('fries')\n",
    "kwtree2.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('smoking', 99)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "result1 = kwtree1.search('my tummy hurts i wonder if the hypnosis has anything to do with it if so its working i get it stop smoking')\n",
    "print(result1)\n",
    "\n",
    "result2 = kwtree2.search('my tummy hurts i wonder if the hypnosis has anything to do with it if so its working i get it stop smoking')\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('smoking', 99)\n"
     ]
    }
   ],
   "source": [
    "results1 = kwtree1.search_all('my tummy hurts i wonder if the hypnosis has anything to do with it if so its working i get it stop smoking')\n",
    "for result in results1:\n",
    "    print(result)\n",
    "    \n",
    "results2 = kwtree2.search_all('my tummy hurts i wonder if the hypnosis has anything to do with it if so its working i get it stop smoking')\n",
    "for result in results2:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KeywordWeight(searchResult, words, weights):\n",
    "    keyword = []\n",
    "    keyword_weight = []\n",
    "    for result in searchResult:\n",
    "        keyword.append(result[0])\n",
    "    for k in keyword:\n",
    "        for i in range(len(words)):\n",
    "            if words[i] == k:\n",
    "                keyword_weight.append(weights[i])\n",
    "                break\n",
    "    return keyword, keyword_weight\n",
    "        \n",
    "def scoring(keyword, weight, real_sentiment, intended_sentiment, sentilevel):\n",
    "    score = 0\n",
    "    for i in range(len(weight)):\n",
    "        score += float(weight[i])\n",
    "    if real_sentiment == intended_sentiment:\n",
    "        discount = sentilevel\n",
    "    else:\n",
    "        discount = -sentilevel\n",
    "    score = score * discount\n",
    "    return score\n",
    "\n",
    "def searcher(filepath):\n",
    "    kwtree_word = []\n",
    "    kwtree_weight = []\n",
    "    f = open(filepath)\n",
    "    for line in f:\n",
    "        word, weight = line.split(' ')\n",
    "        word = word.replace('_', ' ')\n",
    "        kwtree_word.append(word)\n",
    "        weight = weight.split('\\n')[0]\n",
    "        kwtree_weight.append(weight)\n",
    "    f.close()\n",
    "    kwtree = KeywordTree(case_insensitive=True)\n",
    "    for word in kwtree_word:\n",
    "        kwtree.add(word)\n",
    "    kwtree.finalize()\n",
    "    return kwtree, kwtree_word, kwtree_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword: ['junk food']\n",
      "Weight: ['1']\n",
      "score: 0.9711006283760071\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..\\\\sentiment analysis\\\\release')\n",
    "import sentiment_prediction as senti\n",
    "\n",
    "tweet1 = \"i love junk food beacuse they are cheap and delicious.\"\n",
    "\n",
    "modelpath = 'D:\\\\COMP90024_Assignment2\\\\sentiment analysis\\\\sentiment_lstm.h5'\n",
    "pklpath = 'D:\\\\COMP90024_Assignment2\\\\sentiment analysis\\\\training_data\\\\large\\\\sentiment140-freqdist.pkl'\n",
    "analysor = senti.sentianalysor(modelpath, pklpath, stemmer = False)\n",
    "\n",
    "dictionary = '.\\\\fastfood.txt'\n",
    "fastfood_searcher, words, weight = searcher(dictionary)\n",
    "\n",
    "search_result = fastfood_searcher.search_all(tweet1)\n",
    "keyword, keyword_weight = KeywordWeight(search_result, words, weight)\n",
    "print('Keyword:', keyword)\n",
    "print('Weight:', keyword_weight)\n",
    "prediction = analysor.prediction(tweet1)\n",
    "real_senti = prediction[0]\n",
    "sentilevel = prediction[1]\n",
    "intended_sentiment = 'POSITIVE'\n",
    "\n",
    "score =  score = scoring(keyword, keyword_weight, intended_sentiment, real_senti, sentilevel)\n",
    "print('score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 2.6899623579633576\n",
      "score: -1.811632689465635\n",
      "score: 0.21618476496974232\n"
     ]
    }
   ],
   "source": [
    "tweet = [\n",
    "    \"I am the fan of burger king cos its really delicious!\",\n",
    "    \"I don't like burgers since i think they are unhealthy.\",\n",
    "    \"Well i think i'll go to have a cup of coffee.\"\n",
    "]\n",
    "\n",
    "for i in range(len(tweet)):\n",
    "    t = tweet[i]\n",
    "    search_result = fastfood_searcher.search_all(t)\n",
    "    keyword, keyword_weight = KeywordWeight(search_result, words, weight)\n",
    "    prediction = analysor.prediction(t)\n",
    "    real_senti = prediction[0]\n",
    "    sentilevel = prediction[1]\n",
    "    intended_sentiment = 'POSITIVE'\n",
    "    score =  score = scoring(keyword, keyword_weight, intended_sentiment, real_senti, sentilevel)\n",
    "    print('score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get multiple searchers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastfood_dictionary = '.\\\\fastfood.txt'\n",
    "fastfood_searcher, fastfood_words, fastfood_weight = searcher(fastfood_dictionary)\n",
    "\n",
    "smoking_dictionary = '.\\\\smoking.txt'\n",
    "smoking_searcher, smoking_words, smoking_weight = searcher(smoking_dictionary)\n",
    "\n",
    "alcohols_dictionary = '.\\\\alcohols.txt'\n",
    "alcohols_searcher, alcohols_words, alcohols_weight = searcher(alcohols_dictionary)\n",
    "\n",
    "modelpath = 'D:\\\\COMP90024_Assignment2\\\\sentiment analysis\\\\sentiment_lstm.h5'\n",
    "pklpath = 'D:\\\\COMP90024_Assignment2\\\\sentiment analysis\\\\training_data\\\\large\\\\sentiment140-freqdist.pkl'\n",
    "analysor = senti.sentianalysor(modelpath, pklpath, stemmer = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastfood score: 1.8664179067015647\n",
      "smoking score: 0.0\n",
      "alcohols score: 0.0\n"
     ]
    }
   ],
   "source": [
    "tweet1 = 'I am the fan of burger king cos its really delicious!'\n",
    "\n",
    "intended_sentiment = 'POSITIVE'\n",
    "\n",
    "prediction = analysor.prediction(tweet1)\n",
    "real_senti = prediction[0]\n",
    "sentilevel = prediction[1]\n",
    "\n",
    "fd_result = fastfood_searcher.search_all(tweet1)\n",
    "fd_keyword, fd_keyword_weight = KeywordWeight(fd_result, fastfood_words, fastfood_weight)\n",
    "fd_score = scoring(fd_keyword, fd_keyword_weight, intended_sentiment, real_senti, sentilevel)\n",
    "print('fastfood score:', fd_score)\n",
    "\n",
    "smoke_result = smoking_searcher.search_all(tweet1)\n",
    "smoke_keyword, smoke_keyword_weight = KeywordWeight(smoke_result, smoking_words, smoking_weight)\n",
    "smoke_score = scoring(smoke_keyword, smoke_keyword_weight, intended_sentiment, real_senti, sentilevel)\n",
    "print('smoking score:', smoke_score)\n",
    "\n",
    "alcohols_result = alcohols_searcher.search_all(tweet1)\n",
    "alcohols_keyword, alcohols_keyword_weight = KeywordWeight(alcohols_result, alcohols_words, alcohols_weight)\n",
    "alcohols_score = scoring(alcohols_keyword, alcohols_keyword_weight, intended_sentiment, real_senti, sentilevel)\n",
    "print('alcohols score:', alcohols_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastfood score: 0.0\n",
      "smoking score: 0.7204580812454223\n",
      "alcohols score: 0.0\n"
     ]
    }
   ],
   "source": [
    "tweet2 = 'I wanna smoke which makes me feeling sooo good!'\n",
    "\n",
    "intended_sentiment = 'POSITIVE'\n",
    "\n",
    "prediction = analysor.prediction(tweet2)\n",
    "real_senti = prediction[0]\n",
    "sentilevel = prediction[1]\n",
    "\n",
    "fd_result = fastfood_searcher.search_all(tweet2)\n",
    "fd_keyword, fd_keyword_weight = KeywordWeight(fd_result, fastfood_words, fastfood_weight)\n",
    "fd_score = scoring(fd_keyword, fd_keyword_weight, intended_sentiment, real_senti, sentilevel)\n",
    "print('fastfood score:', fd_score)\n",
    "\n",
    "smoke_result = smoking_searcher.search_all(tweet2)\n",
    "smoke_keyword, smoke_keyword_weight = KeywordWeight(smoke_result, smoking_words, smoking_weight)\n",
    "smoke_score = scoring(smoke_keyword, smoke_keyword_weight, intended_sentiment, real_senti, sentilevel)\n",
    "print('smoking score:', smoke_score)\n",
    "\n",
    "alcohols_result = alcohols_searcher.search_all(tweet2)\n",
    "alcohols_keyword, alcohols_keyword_weight = KeywordWeight(alcohols_result, alcohols_words, alcohols_weight)\n",
    "alcohols_score = scoring(alcohols_keyword, alcohols_keyword_weight, intended_sentiment, real_senti, sentilevel)\n",
    "print('alcohols score:', alcohols_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastfood score: 0.0\n",
      "smoking score: 0.0\n",
      "alcohols score: 0.9682081018304826\n"
     ]
    }
   ],
   "source": [
    "tweet3 = 'HAPPY HOURS AGAIN! definately i will go to pub and have a cup of whiskey tonight!'\n",
    "\n",
    "intended_sentiment = 'POSITIVE'\n",
    "\n",
    "prediction = analysor.prediction(tweet3)\n",
    "real_senti = prediction[0]\n",
    "sentilevel = prediction[1]\n",
    "\n",
    "fd_result = fastfood_searcher.search_all(tweet3)\n",
    "fd_keyword, fd_keyword_weight = KeywordWeight(fd_result, fastfood_words, fastfood_weight)\n",
    "fd_score = scoring(fd_keyword, fd_keyword_weight, intended_sentiment, real_senti, sentilevel)\n",
    "print('fastfood score:', fd_score)\n",
    "\n",
    "smoke_result = smoking_searcher.search_all(tweet3)\n",
    "smoke_keyword, smoke_keyword_weight = KeywordWeight(smoke_result, smoking_words, smoking_weight)\n",
    "smoke_score = scoring(smoke_keyword, smoke_keyword_weight, intended_sentiment, real_senti, sentilevel)\n",
    "print('smoking score:', smoke_score)\n",
    "\n",
    "alcohols_result = alcohols_searcher.search_all(tweet3)\n",
    "alcohols_keyword, alcohols_keyword_weight = KeywordWeight(alcohols_result, alcohols_words, alcohols_weight)\n",
    "alcohols_score = scoring(alcohols_keyword, alcohols_keyword_weight, intended_sentiment, real_senti, sentilevel)\n",
    "print('alcohols score:', alcohols_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topicker(tweet, topics, topic_dict_path, intended_sentiments, analysor):\n",
    "    \n",
    "    def scores_checker(scores):\n",
    "        Flag = True\n",
    "        if max(scores) != 0.0:            \n",
    "            for i in range(len(scores)):\n",
    "                if scores[i] != 0.0:\n",
    "                    Flag = False\n",
    "                    break\n",
    "        return Flag\n",
    "    \n",
    "    scores = []\n",
    "    prediction = analysor.prediction(tweet)\n",
    "    real_senti = prediction[0]\n",
    "    sentilevel = prediction[1]\n",
    "    for i in range(len(topic_dict_path)):\n",
    "        intended_sentiment = intended_sentiments[i]\n",
    "        dictionary = topic_dict_path[i]\n",
    "        this_searcher, dict_words, dict_weights = searcher(dictionary)\n",
    "        search_result = this_searcher.search_all(tweet)\n",
    "        keywords, keywords_weights = KeywordWeight(search_result, dict_words, dict_weights)\n",
    "        scores.append(scoring(keywords, keywords_weights, intended_sentiment, real_senti, sentilevel))\n",
    "    if scores_checker(scores):\n",
    "        matched_topic = 'NONE OF THESE'\n",
    "        return matched_topic\n",
    "    else:\n",
    "        max_index = scores.index(max(scores))\n",
    "        matched_topic = topics[max_index]\n",
    "        return matched_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic matched: smoking\n"
     ]
    }
   ],
   "source": [
    "tweet = \"smoking makes me feeling better.\"\n",
    "\n",
    "topics = ['fast food', 'smoking', 'alcohols']\n",
    "topics_dictionary_path = ['fastfood.txt', 'smoking.txt', 'alcohols.txt']\n",
    "intended_sentiments = ['POSITIVE', 'POSITIVE', 'POSITIVE']\n",
    "modelpath = 'D:\\\\COMP90024_Assignment2\\\\sentiment analysis\\\\sentiment_lstm.h5'\n",
    "pklpath = 'D:\\\\COMP90024_Assignment2\\\\sentiment analysis\\\\training_data\\\\large\\\\sentiment140-freqdist.pkl'\n",
    "analysor = senti.sentianalysor(modelpath, pklpath, stemmer = False)\n",
    "\n",
    "matched = topicker(tweet, topics, topics_dictionary_path, intended_sentiments, analysor)\n",
    "print('Topic matched:', matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
